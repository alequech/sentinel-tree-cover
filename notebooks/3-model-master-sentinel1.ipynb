{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "## John Brandt\n",
    "## April 02, 2020\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the TensorFlow model training and prediction used to segment trees for [Restoration Mapper](https://restorationmapper.org). The notebook uses tensorflow 1.13.1 and additionally relies on Keras and tflearn. \n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Package loading\n",
    "- Utility scripts\n",
    "- Hyperparameter definitions\n",
    "- Custom tensorflow layer functions\n",
    "- Tensorflow graph creation\n",
    "- Data loading\n",
    "- Data preprocessing\n",
    "- Equibatch creation\n",
    "- Loss definition\n",
    "- Tensorflow graph initialization\n",
    "- Training\n",
    "- Model validation\n",
    "- Sanity Checks\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0329 08:16:11.294327 4602422720 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0329 08:16:11.309669 4602422720 module_wrapper.py:139] From /Users/john.brandt/Documents/GitHub/restoration-mapper/src/layers/convgru.py:27: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "W0329 08:16:11.410531 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0329 08:16:11.411224 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0329 08:16:11.490484 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0329 08:16:11.524291 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0329 08:16:11.529957 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0329 08:16:11.530620 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/preprocessing/slope.py\n",
    "%run ../src/utils/metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.50\n",
    "\n",
    "ACTIVATION_FUNCTION = 'swish'\n",
    "\n",
    "INITIAL_LR = 5e-5\n",
    "DROPBLOCK_MAXSIZE = 4\n",
    "DECONV = 'upconv'\n",
    "N_CONV_BLOCKS = 1\n",
    "FINAL_ALPHA = 0.33\n",
    "LABEL_SMOOTHING = 0.03\n",
    "BATCH_RENORM = 'renorm'\n",
    "\n",
    "L2_REG = 5e-4\n",
    "BN_MOMENTUM = 0.90\n",
    "BATCH_SIZE = 20\n",
    "MAX_DROPBLOCK = 0.95\n",
    "\n",
    "GRU_FLT = 24\n",
    "OUT_FLT = 48\n",
    "\n",
    "IMAGE_SIZE = 24\n",
    "LABEL_SIZE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cse_block(prevlayer, prefix):\n",
    "    '''Channel excitation and spatial squeeze layer. \n",
    "       Calculates the mean of the spatial dimensions and then learns\n",
    "       two dense layers, one with relu, and one with sigmoid, to rerank the\n",
    "       input channels\n",
    "       \n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the cse_block\n",
    "    '''\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''Implementation of Concurrent Spatial and Channel \n",
    "       ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    \n",
    "        Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): added output of cse and sse block\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "\n",
    "    return x\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {0.1}\")\n",
    "        \"\"\"\n",
    "        cell_fw = ConvLSTMCell(shape = size, filters = flt,\n",
    "                               kernel = [3, 3], forget_bias=1.0, \n",
    "                               activation=tf.tanh, normalize=True, \n",
    "                               peephole=False, data_format='channels_last', reuse=None)\n",
    "        cell_bw = ConvLSTMCell(shape = size, filters = flt,\n",
    "                               kernel = [3, 3], forget_bias=1.0, \n",
    "                               activation=tf.tanh, normalize=True, \n",
    "                               peephole=False, data_format='channels_last', reuse=None)\n",
    "        \"\"\"\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = 0.5, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = 0.5, is_training = train)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"Down block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 clipping_params,\n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None):\n",
    "    '''2D convolution, batch renorm, relu block, 3x3 drop block. \n",
    "       Use_bias must be set to False for batch normalization to work. \n",
    "       He normal initialization is used with batch normalization.\n",
    "       RELU is better applied after the batch norm.\n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "          activation (bool): whether to apply RELU\n",
    "          use_bias (str): whether to use bias. Should always be false\n",
    "\n",
    "         Returns:\n",
    "          bn (tf.Variable): output of Conv2D -> Batch Norm -> RELU\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    bn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    csse_flag = \"CSSE\" if csse else \"No CSSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    \n",
    "    print(\"{} {} Conv 2D {} {} {} {} {}\".format(scope, kernel_size,\n",
    "                                                   bn_flag, activation_flag,\n",
    "                                                   csse_flag, bias_flag, drop_flag))\n",
    "    \n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        conv = Conv2D(filters = filters, kernel_size = (kernel_size, kernel_size),  strides = stride,\n",
    "                      activation = None, padding = 'valid', use_bias = use_bias,\n",
    "                      kernel_regularizer = weight_decay,\n",
    "                      kernel_initializer = tf.keras.initializers.he_normal())(inp)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    #\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = csse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = 17 # 16 for master model\n",
    "reg = tf.contrib.layers.l2_regularizer(L2_REG)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 13, 24, 24, n_bands))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "length2 = tf.reshape(length, (-1,)) # Remove\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For BN, DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax = tf.placeholder(tf.float32, shape = ())\n",
    "rmin = tf.placeholder(tf.float32, shape = ())\n",
    "dmax = tf.placeholder(tf.float32, shape = ())\n",
    "\n",
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deconv_init(filter_size, num_channels):\n",
    "    '''Initializes a kernel weight matrix with a bilinear deconvolution\n",
    "    \n",
    "         Parameters:\n",
    "          filter_size (int): kernel size of convolution\n",
    "          num_channels (int): number of filters for convolution\n",
    "\n",
    "         Returns:\n",
    "          bilinear_init (tf.Variable): [filter_size, filter_size, num_channels] kernel\n",
    "    '''\n",
    "    bilinear_kernel = np.zeros([filter_size, filter_size], dtype=np.float32)\n",
    "    scale_factor = (filter_size + 1) // 2\n",
    "    if filter_size % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(filter_size):\n",
    "        for y in range(filter_size):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * \\\n",
    "                                   (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((filter_size, filter_size, num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "\n",
    "    #assign numpy array to constant_initalizer and pass to get_variable\n",
    "    bilinear_init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "    return bilinear_init\n",
    "\n",
    "def get_deconv2d(inp, filter_count, num_channels, scope, is_training, clipping_params, keep_rate):\n",
    "    '''Creates a deconvolution layer with Conv2DTranspose. Following recent\n",
    "       recommendations to use 4 kernel, 2 stride to avoid artifacts. \n",
    "       Initialize kernel with bilinear upsampling.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input tensorflow layer (B, X, Y, C) shape\n",
    "          filter_count (int): number of filters for convolution\n",
    "          num_channels (int): number of output channels\n",
    "          scope (str): tensorflow variable scope\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): layer with (B, x * 2, y * 2, C) shape\n",
    "          \n",
    "         References:\n",
    "          https://distill.pub/2016/deconv-checkerboard/\n",
    "    '''\n",
    "    bilinear_init = create_deconv_init(4, filter_count)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = filter_count, kernel_size = (4, 4),\n",
    "                                        strides=(2, 2), padding='valid', \n",
    "                                        use_bias = False,\n",
    "                                        kernel_initializer = bilinear_init)(inp)\n",
    "    x = Cropping2D(1)(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = Batch_Normalization(x, training=is_training, scope = scope + \"bn\", clipping_params = clipping_params)\n",
    "    \n",
    "    x = csse_block(x, 'csse_' + scope)\n",
    "    with tf.variable_scope(scope + \"_drop\"):\n",
    "        drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "        x = drop_block(x, is_training)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model uses a UNet architecture where the encoder extracts increasingly abstract features and the decoder upsamples the features to the target resolution.\n",
    "\n",
    "The encoder consists of three blocks:\n",
    "\n",
    "- GRU: A bidirectional convolutional GRU with channel squeeze and spatial excitation, and group normalization, extracts 3x3 features from the multitemporal imagery\n",
    "- Conv1: A MaxPool-conv-swish-groupNorm-csse layer takes the output of the GRU (size 24) and reduces to size 12\n",
    "- Conv2: The output of the MaxPool-conv-swish-csse-DropBlock is a 4x4x80 encoded feature map\n",
    "\n",
    "Some notes on the encoder: \n",
    "\n",
    "- Conv2 does not have a groupNorm layer because its small size (4x4) would make the means and standard deviations highly variable over such small inputs\n",
    "- Conv1 has a groupNorm layer so that the concatenations in the decoder are consistent (1/2 no GN, 1/2 GN)\n",
    "- Conv1 does not have a dropblock because it empirically performs better\n",
    "\n",
    "The decoder consists of two blocks:\n",
    "\n",
    "- Upconv1: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Upconv2: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Output sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 08:16:11.854832 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 12, 24, 24, 17), zoneout: 0.1\n",
      "(3, 3, 41, 48)\n",
      "(3, 3, 41, 48)\n",
      "Down block output shape (?, 24, 24, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 08:16:13.270447 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0329 08:16:13.371920 4602422720 module_wrapper.py:139] From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_median 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "conv_concat 1 Conv 2D Group Norm RELU No CSSE NoBias NoDrop\n",
      "conv1 3 Conv 2D Group Norm RELU CSSE NoBias NoDrop\n",
      "(?, 12, 12, 64)\n",
      "conv2 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Encoded (?, 4, 4, 80)\n",
      "up2 3 Conv 2D Group Norm RELU CSSE NoBias NoDrop\n",
      "up2_out 1 Conv 2D Group Norm RELU No CSSE NoBias DropBlock\n",
      "up3 3 Conv 2D Group Norm RELU CSSE NoBias NoDrop\n",
      "out 3 Conv 2D Group Norm RELU No CSSE NoBias NoDrop\n",
      "Initializing last sigmoid bias with -2.94 constant\n",
      "The output is (?, 8, 8, 64), with a receptive field of 1\n",
      "The output, sigmoid is (?, 14, 14, 1), with a receptive field of 1\n"
     ]
    }
   ],
   "source": [
    "gru_input = inp[:, :12, ...]\n",
    "print(gru_input.shape)\n",
    "print(inp.shape)\n",
    "gru, steps = gru_block(inp = gru_input, length = length2,\n",
    "                            size = [24, 24],\n",
    "                            flt = 24,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "# Median conv\n",
    "median_input = inp[:, -1, ...]\n",
    "median_pad = ReflectionPadding2D((1, 1,))(median_input)\n",
    "median_conv = conv_swish_gn(inp = median_pad, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = 48, clipping_params = clipping_params,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "\n",
    "concat = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = conv_swish_gn(inp = concat, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 1, scope = 'conv_concat', filters = 48, clipping_params = clipping_params,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = False, dropblock = True, weight_decay = None)\n",
    "\n",
    "    \n",
    "# MaxPool-conv-swish-GroupNorm-csse\n",
    "# This block does use GN so that skip connections in decoder block have\n",
    "# one-half GN normalized activations\n",
    "pool1 = MaxPool2D()(concat)\n",
    "pool1 = ReflectionPadding2D((1, 1,))(pool1)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = 64, clipping_params = clipping_params,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(conv1.shape)\n",
    "\n",
    "# MaxPool-conv-swish-csse-DropBlock\n",
    "# This block doesn't use GN because with only a size of 4x4 the mean and stdev are very variable\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = 80, clipping_params = clipping_params,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder 4 - 8, upsample-conv-swish-csse-concat-conv-swish\n",
    "# The decoder doesn't use any GN because empirically this performs better\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = 64, clipping_params = clipping_params,\n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 1, scope = 'up2_out', filters = 64, clipping_params = clipping_params,\n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = False, dropblock = True, weight_decay = None)\n",
    "\n",
    "# Decoder 8 - 14 upsample-conv-swish-csse-concat-conv-swish\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "up3 = ReflectionPadding2D((1, 1,))(up3)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = 48, clipping_params = clipping_params,\n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None)\n",
    "gru_crop = Cropping2D(4)(concat)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = 48, clipping_params = clipping_params,\n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = False, dropblock = False, weight_decay = None)\n",
    "\n",
    "\n",
    "print(\"Initializing last sigmoid bias with -2.94 constant\")\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3) # For focal loss\n",
    "\n",
    "print(f\"The output, sigmoid is {fm.shape}, with a receptive field of {1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 283486 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(f\"This model has {total_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate NDVI, EVI, SAVI, BI, MSAVI2, and SI\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(843, 12, 24, 24, 13)\n",
      "(843, 12, 24, 24, 13)\n",
      "(843, 13, 24, 24, 17)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis\n",
    "\n",
    "import hickle as hkl\n",
    "normalize = False\n",
    "train_x = hkl.load(\"../tile_data/train/train_x.hkl\")\n",
    "train_y = hkl.load(\"../tile_data/train/train_y.hkl\")\n",
    "train_l = hkl.load(\"../tile_data/train/train_l.hkl\")\n",
    "print(train_x.shape)\n",
    "\n",
    "data = pd.read_csv(\"../tile_data/train/train_plot_ids.csv\")\n",
    "if not isinstance(train_x.flat[0], np.floating):\n",
    "    assert np.max(train_x) > 1\n",
    "    train_x = train_x / 65535.\n",
    "    \n",
    "train_x[..., -1] = convert_to_db(train_x[..., -1], 50)\n",
    "train_x[..., -2] = convert_to_db(train_x[..., -2], 50)\n",
    "\n",
    "\n",
    "indices = np.empty((train_x.shape[0], 12, 24, 24, 4))\n",
    "indices[..., 0] = evi(train_x)\n",
    "indices[..., 1] = bi(train_x)\n",
    "indices[..., 2] = msavi2(train_x)\n",
    "indices[..., 3] = grndvi(train_x)\n",
    "\n",
    "train_x = np.concatenate([train_x, indices], axis = -1)\n",
    "\n",
    "med = np.median(train_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "train_x = np.concatenate([train_x, med], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preprocessing\n",
    "\n",
    "*  Identify and remove samples with time steps / channels that have a 0. or 1. value, which indicates missing data\n",
    "*  Identify and remove samples with time steps / channels with no variation, which indicates missing data\n",
    "*  Identify and remove samples with values above or below the allowable values for the band\n",
    "*  Identify and remove samples with null data, or samples with extreme band 0 data (which squash all the \"clean\" samples)\n",
    "*  Smooth per-pixel temporal data with Whittaker smoother, d = 2, lambda = 0.5 to reduce sample noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 2 outlying training data points\n",
      "[494, 620]\n",
      "(841, 13, 24, 24, 17)\n",
      "(841, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "below_1 = [i for i, val in enumerate(train_x[..., :10]) if np.min(val) < -2]\n",
    "above_1 = [i for i, val in enumerate(train_x[..., :10]) if np.max(val) > 2]\n",
    "min_vals = [np.min(val) for i, val in enumerate(train_x[..., :10]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(train_x[..., :10]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(train_x) if np.sum(np.isnan(val)) > 100]\n",
    "oob_vals = [i for i, val in enumerate(train_x) if np.max(val[..., 0]) > 0.7]\n",
    "\n",
    "outliers = below_1 + above_1 + nans + oob_vals\n",
    "outliers = list(set(outliers))\n",
    "print(\"Removing {} outlying training data points\".format(len(outliers)))\n",
    "print(sorted(outliers))\n",
    "train_x = np.delete(train_x, outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "#train_l = np.delete(train_l, outliers)\n",
    "data = data.drop(outliers, 0)\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalize:\n",
    "    means = []\n",
    "    stds = []\n",
    "    for band in tnrange(0, train_x.shape[-1]):\n",
    "        mn = np.mean(train_x[..., band])\n",
    "        std = np.std(train_x[..., band])\n",
    "        normed = (train_x[..., band] - mn) / std\n",
    "        normed[np.where(normed > 3)] = 3.\n",
    "        normed[np.where(normed < -3)] = -3.\n",
    "        train_x[..., band] = normed\n",
    "        print(np.mean(train_x[..., band]))\n",
    "        print(np.std(train_x[..., band]))\n",
    "        means.append(mn)\n",
    "        stds.append(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12700\n",
    "min_all = [0.012558175020981156, 0.025696192874036773, 0.015518425268940261, 0.04415960936903945, 0.040497444113832305, 0.04643320363164721, 0.04924086366063935, 0.04289311055161364, 0.027450980392156862, 0.019760433356221865, 0.0, 0.5432562150454495, 0.2969113383797463, -0.03326967745787883, -0.4014989586557378, -0.023132966289995487, -0.4960341058778109]\n",
    "max_all = [0.21116960402838178, 0.30730144197756926, 0.4478065156023499, 0.5342488746471351, 0.4942702372777905, 0.5072556649118791, 0.5294422827496758, 0.5418631265735866, 0.6813458457312886, 0.6285648889906157, 0.4208438239108873, 0.9480767549203932, 0.8130214090572532, 0.7444347421954634, 0.3268904303046983, 0.6872429594867983, 0.7129084148772861]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535af52439464a748f3852d9fef69aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0000000000000002, 1.0000000000000002]\n",
      "[0.012558175020981156, 0.025696192874036773, 0.015518425268940261, 0.04415960936903945, 0.040497444113832305, 0.04643320363164721, 0.04924086366063935, 0.04289311055161364, 0.027450980392156862, 0.019760433356221865, 0.0, 0.5432562150454495, 0.2969113383797463, -0.03326967745787883, -0.4014989586557378, -0.023132966289995487, -0.4960341058778109] [0.21116960402838178, 0.30730144197756926, 0.4478065156023499, 0.5342488746471351, 0.4942702372777905, 0.5072556649118791, 0.5294422827496758, 0.5418631265735866, 0.6813458457312886, 0.6285648889906157, 0.4208438239108873, 0.9480767549203932, 0.8130214090572532, 0.7444347421954634, 0.3268904303046983, 0.6872429594867983, 0.7129084148772861]\n"
     ]
    }
   ],
   "source": [
    "if not normalize:\n",
    "    #min_all = []\n",
    "    #max_all = []\n",
    "    for band in tnrange(0, train_x.shape[-1]):\n",
    "        #mins = np.percentile(train_x[:, ..., band], 1)\n",
    "        #maxs = np.percentile(train_x[:, ..., band], 99)\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        train_x[..., band] = np.clip(train_x[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (train_x[..., band] - midrange) / (rng / 2)\n",
    "        train_x[..., band] = standardized\n",
    "\n",
    "        #min_all.append(mins)\n",
    "        #max_all.append(maxs)\n",
    "\n",
    "    print(\"The data has been scaled to [{}, {}]\".format(np.min(train_x), np.max(train_x)))\n",
    "    print(min_all, max_all)\n",
    "    #np.save(\"min_all.npy\", min_all)\n",
    "    #np.save(\"max_all.npy\", max_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment training data\n",
    "\n",
    "Horizontal and vertical flips for 4x augmentation.\n",
    "\n",
    "**To do**\n",
    "*  Random guassian noise\n",
    "*  Brightness, contrast\n",
    "*  Region swaps (randomply position positive samples at different locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 outliers: []\n",
      "[]\n",
      "[]\n",
      "(1000, 13, 24, 24, 17)\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "test_x = hkl.load(\"../tile_data/test/test_x.hkl\")\n",
    "test_y = hkl.load(\"../tile_data/test/test_y.hkl\")\n",
    "test_data = pd.read_csv(\"../tile_data/test/test_plot_ids.csv\")\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    test_x[..., 11:15] = (test_x[..., 11:15] * 2) - 1\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 50)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 50)\n",
    "\n",
    "\n",
    "\n",
    "s1 = test_x[..., -2:]\n",
    "s1_med = s1[:, -1, ...]\n",
    "s1_med = np.tile(s1_med[:, np.newaxis, ...], (1, 13, 1, 1, 1,))\n",
    "s1[s1 == 1] = s1_med[s1 == 1]\n",
    "test_x[..., -2:] = s1\n",
    "assert test_x.shape[0] == len(test_data)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "\n",
    "\n",
    "#outliers = [564, 782, 813, 904]\n",
    "#print([x for x in test_data['plot_id'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "outliers = test_data[test_data['plot_id'].isin(\n",
    "    [135542383, 136434961, 136435074, 136752744, 136752846, 136752868, 135702506, 135807759])]\n",
    "outliers = list(outliers.index)\n",
    "print(outliers)\n",
    "print([x for x in test_data['plot_id'].iloc[outliers]])\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "test_x[..., 14] = grndvi(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalization\n",
    "normalize = False\n",
    "if normalize:\n",
    "    print(\"Normalizing data\")\n",
    "    for band in tnrange(0, test_x.shape[-1]):\n",
    "        print(f\"{band}, mean, {abs(np.mean(test_x[..., band]) - means[band])}\")\n",
    "        print(f\"{band}, std, {abs(np.std(test_x[..., band]) - stds[band])}\")\n",
    "        normed = (test_x[..., band] - means[band]) / stds[band]\n",
    "        normed[np.where(normed > 3)] = 3.\n",
    "        normed[np.where(normed < -3)] = -3.\n",
    "        test_x[..., band] = normed\n",
    "\n",
    "        means.append(mn)\n",
    "        stds.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been scaled to [-1.0000000000000002, 1.0000000000000002]\n"
     ]
    }
   ],
   "source": [
    "if not normalize:\n",
    "    for band in range(0, test_x.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "        test_x[..., band] = standardized\n",
    "    \n",
    "    print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test characteristics:\n",
      "Train mean Y 52.943\n",
      "Test STD Y 73.93116900874759\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and test characteristics:\")\n",
    "print(\"Train mean Y {}\".format(np.mean([np.sum(x) for x in test_y])))\n",
    "print(\"Test STD Y {}\".format(np.std([np.sum(x) for x in test_y])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 4.549999999999983, 10.0, 17.0, 26.0, 46.0]\n",
      "There are 182 zeros\n"
     ]
    }
   ],
   "source": [
    "sums = np.sum(train_y, axis = (1, 2))\n",
    "percents = [np.percentile(sums, x) for x in range(30, 100, 9)]\n",
    "print(percents)\n",
    "print(\"There are {} zeros\".format(len(np.argwhere(sums == 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[215, 57, 41, 39, 26, 30, 3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list of arrays):\n",
    "\n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "def equibatch(train_ids, p = percents):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          train_ids (list):\n",
    "          p (list):\n",
    "\n",
    "         Returns:\n",
    "          equibatches (list):\n",
    "    '''\n",
    "    percents = [9.0, 16.0, 27.0, 40.0, 64.0, 102.0, 157.0] # november\n",
    "    #percents = [9.0, 19.0, 28.0, 40.0, 62.0, 100.0, 155.0] # january\n",
    "    percents = [9.0, 17.0, 27.0, 40.0, 65.0, 103.0, 155.0] # january - percentiles\n",
    "    np.random.shuffle(train_ids)\n",
    "    ix = train_ids\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    ids0 = [x for x, z in zip(ix, percs) if z <= 2]\n",
    "    ids30 = [x for x, z in zip(ix, percs) if 2 < z <= percents[0]]\n",
    "    ids40 = [x for x, z in zip(ix, percs) if percents[0] < z <= percents[1]]\n",
    "    ids50 = [x for x, z in zip(ix, percs) if percents[1] < z <= percents[2]]\n",
    "    ids60 = [x for x, z in zip(ix, percs) if percents[2] < z <= percents[3]]\n",
    "    ids70 = [x for x, z in zip(ix, percs) if percents[3] < z <= percents[4]]\n",
    "    ids80 = [x for x, z in zip(ix, percs) if percents[4] < z <= percents[5]]\n",
    "    ids90 = [x for x, z in zip(ix, percs) if percents[5] < z <= percents[6]]\n",
    "    ids100 = [x for x, z in zip(ix, percs) if percents[6] < z]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(ids0), len(ids30), len(ids40), len(ids50), len(ids60), len(ids70),\n",
    "             len(ids80), len(ids90), len(ids100)]\n",
    "    print(maxes)\n",
    "    cur_ids = [0] * len(maxes)\n",
    "    iter_len = len(train_ids)//(len(maxes))\n",
    "    for i in range(0, iter_len):\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 1:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [ids0[cur_ids[0]],\n",
    "                    ids30[cur_ids[1]], ids40[cur_ids[2]],\n",
    "                    ids50[cur_ids[3]], ids60[cur_ids[4]], \n",
    "                    ids70[cur_ids[5]], ids80[cur_ids[6]],\n",
    "                    ids90[cur_ids[7]], ids100[cur_ids[8]]]\n",
    "        \n",
    "        \n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    return new_batches\n",
    "\n",
    "batch = equibatch(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(15, 6)\n",
    "sns.distplot(np.sum(train_y, axis = (1, 2)), bins = 50, kde = False, ax = ax1)\n",
    "ax1.set_title('Original distribution')\n",
    "ax2.set_title('Equibatch distribution')\n",
    "sns.distplot(np.sum(train_y[batch], axis = (1, 2)),\n",
    "             bins = 50, kde = False, ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example equibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[4:8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[8:12]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight cross entropy by effective number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17782.0 66640\n",
      "Beta: 0.999\n",
      "[340.         90.7244898]\n",
      "[0.28835075 0.08677216]\n",
      "Neg and pos weights: [0.23131662 0.76868338]\n",
      "3.323078938501377\n"
     ]
    }
   ],
   "source": [
    "sum_pos = np.sum(train_y[batch], axis = (1, 2))\n",
    "sum_pos = sum_pos[sum_pos != 196]\n",
    "n_pos = len(train_y) - len(sum_pos)\n",
    "sum_pos = np.sum(sum_pos)\n",
    "sum_neg = np.sum(train_y[batch], axis = (1, 2))\n",
    "sum_neg = sum_neg[sum_neg != 0]\n",
    "n_neg = len(train_y) - len(sum_neg)\n",
    "sum_neg = (len(train_y) - (n_neg + n_pos)) * 196\n",
    "print(sum_pos, sum_neg)\n",
    "beta = 0.999\n",
    "print(\"Beta: {}\".format(beta))\n",
    "samples_per_cls = np.array([sum_neg, sum_pos]) / 196\n",
    "print(samples_per_cls)\n",
    "effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "print(effective_num)\n",
    "weights = (1.0 - beta) / np.array(effective_num)\n",
    "weights = weights / np.sum(weights)\n",
    "print(\"Neg and pos weights: {}\".format(weights))\n",
    "weight = weights[1] / weights[0]\n",
    "print(weight)\n",
    "weight = 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: The positive is: 0.2313166181385197\n",
      "Baseline: The negative is: 0.7686833818614803\n",
      "\n",
      "\n",
      "Balanced: The positive is: 0.39323825083548347\n",
      "Balanced: The negative is: 0.7686833818614803\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline: The positive is: {}\".format(weights[0]))\n",
    "print(\"Baseline: The negative is: {}\".format(weights[1]))\n",
    "print(\"\\n\")\n",
    "print(\"Balanced: The positive is: {}\".format(weight*weights[0]))\n",
    "print(\"Balanced: The negative is: {}\".format(weights[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loss definition\n",
    "\n",
    "The current best loss is a combination of weighted binary cross entropy and per-image Lovasz-Softmax, with a loss schedule with the latter becoming more important each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def calc_mask(seg):\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "    loss_importance = np.array([x for x in range(0, 197, 1)])\n",
    "    loss_importance = loss_importance / 196\n",
    "    loss_importance = np.expm1(loss_importance)\n",
    "    loss_importance[:30] = 0.\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    res[np.logical_and(res < 2, res > 0)] = 0.5\n",
    "    res[np.logical_or(res >= 2, res <= 0)] = 1.\n",
    "    return res\n",
    "\n",
    "def calc_mask_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    bce_batch = np.array([calc_mask(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "    return bce_batch\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    #Utility function for calc_dist_map_batch that calculates the loss\n",
    "    #   importance per pixel based on the surface distance function\n",
    "    \n",
    "     #    Parameters:\n",
    "    #      seg (arr):\n",
    "     #     \n",
    "    #     Returns:\n",
    "    #      res (arr):\n",
    "    #\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.25\n",
    "                    ones[x + 1, y] = 0.25\n",
    "                    ones[x, y + 1] = 0.25\n",
    "                    ones[x, y - 1] = 0.25\n",
    "                    ones[x - 1, y + 1] = 0.25\n",
    "                    ones[x + 1, y + 1] = 0.25\n",
    "                    ones[x + 1, y - 1] = 0.25\n",
    "                    ones[x -1, y - 1] = 0.25\n",
    "\n",
    "    if posmask.any():\n",
    "        \n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        #res[np.where(np.isclose(res, 1.41421356, rtol = 1e-2))] = loss_importance[sums]\n",
    "        \n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_surf(y_true, y_pred, alpha, weight, beta):\n",
    "    \n",
    "    #lv = lovasz_softmax(probas = y_pred,\n",
    "    #                    labels = tf.reshape(y_true, (-1, 14, 14)), \n",
    "    #                    classes=[1],\n",
    "    #                    per_image=True) \n",
    "    \n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(y_true, y_pred)\n",
    "\n",
    "    #bce_mask = tf.math.reduce_sum(y_true, axis = (1, 2, 3))\n",
    "    #bce_mask = tf.cast(bce_mask, tf.float32)\n",
    "    #bce_mask_low = tf.math.less(bce_mask, tf.constant([1.]))\n",
    "    #bce_mask_high = tf.math.greater(bce_mask, tf.constant([195.]))\n",
    "    \n",
    "    #bce_mask_low = tf.cast(bce_mask_low, tf.float32)\n",
    "    #bce_mask_high = tf.cast(bce_mask_high, tf.float32)\n",
    "    #bce_mask = bce_mask_low + bce_mask_high\n",
    "    #print(\"BCE mask\", bce_mask.shape)\n",
    "    #surface = (surface * (1 - bce_mask)) + (bce_mask * bce)\n",
    "    surface = tf.reduce_mean(surface)\n",
    "    \n",
    "    \n",
    "    #lovasz = (lv * lv_mask) + (bce * bce_mask)\n",
    "    #lovasz = tf.reduce_mean(lovasz)\n",
    "    #lovasz_portion = (1 - alpha) * lovasz\n",
    "    #lovasz_portion = lovasz_portion * beta\n",
    "    bce = tf.reduce_mean(bce)\n",
    "\n",
    "    bce = (1 - alpha) * bce\n",
    "    #bce = bce * (1 - beta)\n",
    "    surface_portion = alpha * surface\n",
    "    result = bce + surface_portion\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 23 # 14\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(14, 5)\n",
    "sns.heatmap(calc_dist_map(train_y[idx]), ax = ax1)\n",
    "ax2.set_title('Ground truth Y')\n",
    "ax1.set_title('Boundary loss mask')\n",
    "sns.heatmap(train_y[idx], ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'all': [0, 1150]}\n",
    "\n",
    "def dice_loss_tolerance(y_true, y_pred):\n",
    "    numerator_data = np.zeros_like(y_true)\n",
    "    for x in range(y_true.shape[0]):\n",
    "        for y in range(y_true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([y_true.shape[0], y+2])\n",
    "            max_x = np.min([y_true.shape[0], x+2])\n",
    "            if y_true[x, y] == 1:\n",
    "                numerator_data[x, y] = np.max(y_pred[min_x:max_x, min_y:max_y])\n",
    "                \n",
    "    numerator = 2 * np.sum(y_true * numerator_data, axis=-1)\n",
    "    denominator = np.sum(y_true + y_pred, axis=-1)\n",
    "    return (numerator + 1) / (denominator + 1)\n",
    "                    \n",
    "            \n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(country, al = 0.4, canopy_thresh = 100, lower_thresh = 0):\n",
    "    '''Calculates the following metrics for an input country, based on\n",
    "       indexing of the country dictionary:\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          country (str):\n",
    "          al (float):\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    print(canopy_thresh)\n",
    "    start_idx = 0\n",
    "    stop_idx = len(test_x)\n",
    "    best_f1 = 0\n",
    "    best_dice = 0\n",
    "    best_thresh = 0\n",
    "    hausdorff = 0\n",
    "    relaxed_f1 = 0\n",
    "    preds = []\n",
    "    vls = []\n",
    "    trues = []\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197):\n",
    "            if np.sum(test_y[test_sample]) >= ((lower_thresh / 100) * 197):\n",
    "                x_input = test_x[test_sample].reshape(1, 13, 24, 24, n_bands)\n",
    "                x_median_input = calc_median_input(x_input)\n",
    "                y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                              #inp_median: x_median_input,\n",
    "                                                              length: np.full((1, 1), 12),\n",
    "                                                              is_training: False,\n",
    "                                                              clipping_params['rmax']: 5,\n",
    "                                                              clipping_params['rmin']: 0,\n",
    "                                                              clipping_params['dmax']: 3,\n",
    "                                                              labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                              loss_weight: 1.5,\n",
    "                                                              alpha: al,\n",
    "                                                              })\n",
    "                preds.append(y.reshape((14, 14)))\n",
    "                vls.append(vl)\n",
    "                trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "    dice_losses = []\n",
    "    for thresh in range(8, 10):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "            if thresh == 8:\n",
    "                if np.sum(true + pred) > 0:\n",
    "                    dice_losses.append(0.5)\n",
    "                   # dice_losses.append(dice_loss_tolerance(np.array(true), np.array(pred)))\n",
    "                else:\n",
    "                    dice_losses.append(1.)\n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            haus = np.zeros((len(preds), ))\n",
    "            for sample in range(len(preds)):\n",
    "                pred = np.copy(preds[sample])\n",
    "                pred[np.where(pred >= thresh*0.05)] = 1\n",
    "                pred[np.where(pred < thresh*0.05)] = 0\n",
    "                true = trues[sample]\n",
    "                #dists = compute_surface_distances(np.array(true).reshape(14, 14, 1).astype(int),\n",
    "                #                                  np.array(pred).reshape(14, 14, 1).astype(int),\n",
    "                #                                  [1, 1, 1])\n",
    "                #if np.sum(true + pred) > 0:\n",
    "                #    haus_i = compute_robust_hausdorff(dists, 50)\n",
    "                #    if not np.isinf(haus_i):\n",
    "                #        haus[sample] = haus_i\n",
    "                #if np.sum(true + pred) == 0:\n",
    "                #    haus[sample] = 0.\n",
    "                    \n",
    "            dices = np.mean(dice_losses)\n",
    "            haus = np.mean(haus)\n",
    "            best_dice = 0.5\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "            best_haus = 0.5\n",
    "    print(f\"{country}: Val loss: {np.around(np.mean(vls), 3)}\"\n",
    "          f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" D: {np.around(np.mean(best_dice), 3)} H: {np.around(best_haus, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error, best_haus, np.mean(best_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data for a total of 4 x augmentation\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids]\n",
    "    y = train_y[batch_ids]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i] = x[i]\n",
    "            y_batch[i] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i] = np.flip(x[i], 1)\n",
    "            y_batch[i] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i] = np.flip(x[i], 2)\n",
    "            y_batch[i] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([0, 1, 2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median_input(x_batch):\n",
    "    x_median = np.percentile(x_batch, 25, axis = (1))\n",
    "    return x_median\n",
    "\n",
    "x_batch_med = calc_median_input(x_batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with: \n",
      " 0.5 zone out \n",
      " 0.0005 l2 \n",
      "5e-05 initial LR \n",
      " 283486 parameters\n",
      "Check the learning rates u dweeb\n"
     ]
    }
   ],
   "source": [
    "# 266k-master-adabound-5e-4to5e-2 is really 3e-4 to \n",
    "FRESH_START = True\n",
    "best_val = 0.2\n",
    "\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100\n",
    "LEARNING_RATE = 3e-3\n",
    "#test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "print(f\"Starting model with: \\n {ZONE_OUT_PROB} zone out \\n {L2_REG} l2 \\n\"\n",
    "      f\"{INITIAL_LR} initial LR \\n {total_parameters} parameters\")  \n",
    "\n",
    "print(\"Check the learning rates u dweeb\")\n",
    "    \n",
    "if FRESH_START:\n",
    "    #print(f\"Restarting training from scratch on {len(train_ids)} train and {len(test_ids)} test samples\")\n",
    "    optimizer = AdaBoundOptimizer(1e-3, ft_lr)\n",
    "    train_loss = lovasz_surf(tf.reshape(labels, (-1, 14, 14, 1)), \n",
    "                             fm, weight = loss_weight, \n",
    "                             alpha = alpha, beta = beta_)\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    if len(tf.losses.get_regularization_losses()) > 0:\n",
    "        print(\"Adding L2 loss\")\n",
    "        train_loss = train_loss + l2_loss\n",
    "    ft_optimizer = tf.train.MomentumOptimizer(ft_lr, momentum = 0.8, use_nesterov = True)\n",
    "    test_loss = lovasz_surf(tf.reshape(labels, (-1, 14, 14, 1)),\n",
    "                            fm, weight = loss_weight, \n",
    "                            alpha = alpha, beta = beta_)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss)   \n",
    "        ft_op = ft_optimizer.minimize(train_loss)\n",
    "        \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver(max_to_keep = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting anew\n"
     ]
    }
   ],
   "source": [
    "model_path  = \"models/rmapper/266k-master-800alpha-sentinel1-zo-0.5-db-.15/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../models/master-2021-13000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring\n"
     ]
    }
   ],
   "source": [
    "#path = f'{model_path}95-91-1/'\n",
    "print(\"Restoring\")\n",
    "saver.restore(sess, tf.train.latest_checkpoint(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f12b9cc6ac69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc1r1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train losses - 0.33 a, 1.5 w, 1e-4, 1e-3 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end),\n\u001b[0m\u001b[1;32m      9\u001b[0m                ax = c1r1)\n\u001b[1;32m     10\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 80\n",
    "\n",
    "f, ((c1r1, c1r2), (c2r1, c2r2)) = plt.subplots(2, 2, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(\"Train losses - 0.33 a, 1.5 w, 1e-4, 1e-3 \")\n",
    "l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end),\n",
    "               ax = c1r1)\n",
    "l1.set(ylim=(0.17, .21))\n",
    "\n",
    "c1r2.set_title(\"Nov 25 - F1 score\")\n",
    "f =sns.scatterplot(y = metrics[5, start:end], x = np.arange(start, end),\n",
    "               ax = c1r2)\n",
    "f.set(ylim=(0.88, .912))\n",
    "\n",
    "c2r1.set_title(\"Test losses\")\n",
    "l = sns.scatterplot(y = metrics[1, start:end], x = np.arange(start, end),\n",
    "               ax = c2r1)\n",
    "l.set(ylim=(0.215, .23))\n",
    "\n",
    "c2r2.set_title(\"Errors\")\n",
    "e = sns.scatterplot(y = metrics[2, start:end] / 2, x = np.arange(start, end),\n",
    "               ax = c2r2)\n",
    "e.set(ylim=(3, None))\n",
    "\n",
    "\"\"\"\n",
    "c2r3.set_title(\"Hausdorff\")\n",
    "sns.scatterplot(y = metrics[3, start:end], x = np.arange(start, end),\n",
    "               ax = c2r3)\n",
    "\n",
    "c1r3.set_title(\"Dice\")\n",
    "sns.scatterplot(y = metrics[4, start:end], x = np.arange(start, end),\n",
    "               ax = c1r3)\n",
    "\"\"\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure that the equibatch is working with the augmentation\n",
    "BATCH_SIZE = 32\n",
    "randomize = equibatch(train_ids)\n",
    "sum_no_equibatch = []\n",
    "sum_equibatch = []\n",
    "for k in tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "    rand = [x for x in range(len(randomize))]\n",
    "    batch_ids = rand[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "    _, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "    sum_no_equibatch.append(np.sum(y_batch))\n",
    "    \n",
    "for k in tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "    batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "    _, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "    sum_equibatch.append(np.sum(y_batch))\n",
    "    \n",
    "print(\"No equibatch SD: {}\".format(np.std(np.array(sum_no_equibatch))))\n",
    "print(\"Equibatch SD: {}\".format(np.std(np.array(sum_equibatch))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# September changes\n",
    "- Implement equibatch\n",
    "- Implement 4x4 FPA, with CSSE in middle blocks\n",
    "- Reduce label smoothing from 0.08 to 0.03\n",
    "- reduce dropblock to 0.95 from 0.8\n",
    "\n",
    "# Things to test\n",
    "- Concatenating mean after GRU\n",
    "- Turning of sse in GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_lr(epoch):\n",
    "    path = f'{model_path}28-88-5/'\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "    op = ft_op\n",
    "    print(\"Using SGDM\")\n",
    "    BATCH_SIZE = 20\n",
    "    test_lrs = [1e-4, 2e-4, 3e-4, 5e-4, 8e-4, 1e-3,\n",
    "                2e-3, 3e-3, 4e-3, 5e-3, 6e-3, 7e-3, 8e-3, 1e-2]\n",
    "    losses = []\n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    randomize = equibatch(train_ids)\n",
    "    \n",
    "    for k in tnrange(len(test_lrs)):\n",
    "        loss_i = []\n",
    "        for batch in tnrange(15):\n",
    "            batch_ids = randomize[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "            x_median_input = calc_median_input(x_batch)\n",
    "            ft_learning_rate = test_lrs[k]\n",
    "            rmax_epoch, dmax_epoch, rmin_epoch = calc_renorm_params(epoch, len(train_y), BATCH_SIZE, k)\n",
    "            opt, tr = sess.run([op, loss],\n",
    "                              feed_dict={inp: x_batch,\n",
    "                                         #inp_median: x_median_input,\n",
    "                                         length: np.full((BATCH_SIZE, 1), 12),\n",
    "                                         labels: y_batch,\n",
    "                                         is_training: True,\n",
    "                                         clipping_params['rmax']: rmax_epoch,\n",
    "                                         clipping_params['rmin']: rmin_epoch,\n",
    "                                         clipping_params['dmax']: dmax_epoch,\n",
    "                                         loss_weight: 1.5,\n",
    "                                         keep_rate: np.max(((1. - (i * 0.003)), 0.90)),\n",
    "                                         alpha: np.min([epoch * 0.01, 0.33]),\n",
    "                                         beta_: be,\n",
    "                                         ft_lr: ft_learning_rate,\n",
    "                                         })\n",
    "            loss_i.append(tr)\n",
    "        losses.append(np.mean(loss_i))\n",
    "        print(test_lrs[k], np.mean(loss_i))\n",
    "    return losses, test_lrs\n",
    "\n",
    "#losses, test_lrs = find_lr(epoch = 28)\n",
    "#sns.scatterplot(np.log10(test_lrs), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "best_val = 0.72\n",
    "fine_tune = False\n",
    "countries['all'] = [0, len(test_x)]\n",
    "ft_epochs = 0\n",
    "ft_learning_rate = .03\n",
    "\n",
    "for i in range(96, 125):\n",
    "    al = np.min( [0.01 * (i - 1), 0.33] )\n",
    "    #test_al = 0.3\n",
    "    be = 0.0\n",
    "    \n",
    "    test_al = al\n",
    "    #test_al = 0.33 if al < 0.8 else al\n",
    "    print(ft_epochs)\n",
    "    if fine_tune == True:\n",
    "        op = ft_op\n",
    "        #ft_epochs += 1\n",
    "        #if ft_epochs % 20 == 0:\n",
    "        #    ft_learning_rate /= 2\n",
    "        #    print(\"DIVIDING LR\")\n",
    "        print(f\"FINE TUNING WITH {ft_learning_rate} LR\")\n",
    "    else:\n",
    "        op = train_op\n",
    "        \n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    randomize = equibatch(train_ids)\n",
    "    print(f\"starting epoch {i}, alpha: {al}, beta: {be} drop: {np.max(((1. - (i * 0.005)), 0.90))}\"\n",
    "         f\" Learning rate: {ft_learning_rate}\")\n",
    "    \n",
    "    loss = train_loss\n",
    "    BATCH_SIZE = 20\n",
    "    test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    \n",
    "    for k in tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        opt, tr = sess.run([op, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: np.full((BATCH_SIZE, 1), 12),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     clipping_params['rmax']: 5,\n",
    "                                     clipping_params['rmin']: 0,\n",
    "                                     clipping_params['dmax']: 3,\n",
    "                                     loss_weight: 1.5,\n",
    "                                     keep_rate: np.max(((1. - (i * 0.005)), 0.90)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(f\"Epoch {i}: Loss {np.around(np.mean(losses[:-1]), 3)}\")\n",
    "    run_metrics = False\n",
    "    if (i > 60) and (i % 1) == 0:\n",
    "        run_metrics = True\n",
    "    elif i % 2 == 0:\n",
    "        run_metrics = True\n",
    "    if run_metrics:\n",
    "        val_loss, f1, error, haus, dice = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "        metrics[0, i] = np.mean(losses[:-1])\n",
    "        metrics[1, i] = val_loss\n",
    "        metrics[2, i] = error\n",
    "        metrics[3, i] = haus\n",
    "        metrics[4, i] = dice\n",
    "        metrics[5, i] = f1\n",
    "        if f1 < (best_val - 0.002):\n",
    "            ft_epochs += 1\n",
    "        if f1 > (best_val - 0.02):\n",
    "            print(f\"Saving model with {f1}\")\n",
    "            np.save(f\"{model_path}metrics.npy\", metrics)\n",
    "            os.mkdir(f\"{model_path}{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/\")\n",
    "            save_path = saver.save(sess, f\"{model_path}{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/model\")\n",
    "            if f1 > best_val:\n",
    "                best_val = f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da64254c72d4da8a1b13780f25e2d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ids = [x for x in range(len(test_x))]\n",
    "diffs = []\n",
    "for idx in tnrange(len(test_ids)):\n",
    "    x_input = test_x[idx].reshape(1, 13, 24, 24, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1, 1), 12),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y[np.where(y > 0.45)] = 1.0\n",
    "    y[np.where(y < 0.45)] = 0.\n",
    "    diff = np.sum(y) - np.sum(test_y[idx])\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n",
    "\n",
    "#test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fbfd2b252918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#start = len(test_ids) - 99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "test_ids = [x for x in range(test_x.shape[0])]\n",
    "start = 800\n",
    "#start = len(test_ids) - 99\n",
    "test_data.iloc[start]['lat'], test_data.iloc[start]['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "[880, 881, 882, 883, 884, 885, 886, 887]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(start/len(test_ids))\n",
    "test_ids = [x for x in range(test_x.shape[0])]\n",
    "test_ids = sorted(test_ids)\n",
    "#test_ids = np.argwhere(abs(np.array(diffs)) > 25)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 24, 24, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1, 1), 12),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    #print(i, int(test_data.iloc[i]['plot_id']),\n",
    "     #     test_data.iloc[i]['lat'], test_data.iloc[i]['long'])\n",
    "    #print(i, (list(test_data.iloc[idx, 1])[0], list(test_data.iloc[idx, 2])[0]), diffs[i[0]])\n",
    "    #y, mapshape = aggregate_maxes(test_y[idx], y)\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 \n",
    "\n",
    "# 123, 334, 680, 875, 917, 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(len(train_y))]\n",
    "diffs = []\n",
    "for idx in tnrange(len(train_ids)):\n",
    "    x_input = train_x[idx].reshape(1, 13, 24, 24, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1, 1), 12),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y[y > 0.45] = 1.0\n",
    "    y[y < 0.45] = 0.\n",
    "    diff = np.sum(y) - np.sum(train_y[idx])\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(train_x.shape[0])]\n",
    "start = len(train_ids) - 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593, 594, 595, 596, 597, 598, 599, 600]\n",
      "593 139419981 -18.420013139656934 -40.70402618000001\n",
      "594 139419982 13.085921709747634 -85.96612962\n",
      "595 139419983 13.08476559974766 -85.97121251000002\n",
      "596 139419984 13.080918549747725 -85.98012251\n",
      "597 139419985 13.075476869747824 -85.97340512999997\n",
      "598 139419986 13.073005189747866 -85.96806311\n",
      "599 139419987 13.068241229747949 -85.97143176999998\n",
      "600 139419990 13.10751206974725 -85.90022056999999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_ids = np.argwhere(abs(np.array(diffs)) > 35)\n",
    "\n",
    "matrix_ids = [train_ids[start], train_ids[start + 1], train_ids[start + 2],\n",
    "             train_ids[start + 3], train_ids[start + 4],\n",
    "             train_ids[start + 5], train_ids[start + 6], train_ids[start + 7]]\n",
    "preds = []\n",
    "trues = []\n",
    "#print(start//4)\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 24, 24, n_bands)\n",
    "    #median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1, 1), 12),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    \n",
    "    #y, _ = aggregate_maxes(train_y[idx], y)\n",
    "    \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    \n",
    "    #print(idx, (list(data.iloc[idx, 1])[0], list(data.iloc[idx, 2])[0]), diffs[idx[0]])\n",
    "    print(idx, data.iloc[i, 0], data.iloc[i, 1],\n",
    "          data.iloc[i, 2])\n",
    "    trues.append(true)\n",
    "    \n",
    "start += 8\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
