{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter notebook predicts large-area tiles downloaded in `4a-download-large-area` with a trained model from `3-model-master`. The notebook is broken down into the following sections:\n",
    "\n",
    "   * **Model loading**:\n",
    "   * **Coordinate identification**\n",
    "   * **Tiling**\n",
    "   * **Loading and predicting**\n",
    "   * **Mosaicing**\n",
    "   * **Writing TIF**\n",
    "   * **Writing COG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "import hickle as hkl\n",
    "from time import sleep\n",
    "\n",
    "%run ../src/downloading/utils.py\n",
    "%run ../src/models/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSCAPE = 'elsalvador-country'\n",
    "YEAR = 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-90.08, 13.145) ../project-monitoring/el-salvador/sonsonate/acajutla/2018/output/\n"
     ]
    }
   ],
   "source": [
    "database = pd.read_csv(\"../project-monitoring/database.csv\")\n",
    "coords = database[database['landscape'] == LANDSCAPE]\n",
    "path = coords['path'].tolist()[0]\n",
    "coords = (float(coords['longitude']), float(coords['latitude']))\n",
    "\n",
    "IO_PARAMS = {'prefix': '../',\n",
    "             'bucket': 'restoration-monitoring',\n",
    "             'coords': coords,\n",
    "             'bucket-prefix': '',\n",
    "             'path': path}\n",
    "\n",
    "OUTPUT = IO_PARAMS['prefix'] + IO_PARAMS['path'] + str(YEAR) + '/output/'\n",
    "TIF_OUTPUT = IO_PARAMS['prefix'] + IO_PARAMS['path'] + str(YEAR) + \".tif\"\n",
    "INPUT = IO_PARAMS['prefix'] + IO_PARAMS['path'] + str(YEAR) + '/processed/'\n",
    "\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.makedirs(OUTPUT)\n",
    "    \n",
    "print(coords, OUTPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../models/master-2021-s1/'\n",
    "new_saver = tf.train.import_meta_graph(path + 'model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "\n",
    "\n",
    "#inp_median = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Tiling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 81 90 90 361\n"
     ]
    }
   ],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "\n",
    "arr = fspecial_gauss(14, 2)\n",
    "arr = arr[:7, :7]\n",
    "\n",
    "SIZE = 10\n",
    "SIZE_N = SIZE*SIZE\n",
    "SIZE_UR = (SIZE - 1) * (SIZE - 1)\n",
    "SIZE_R = (SIZE - 1) * SIZE\n",
    "SIZE_U = SIZE_R\n",
    "TOTAL = SIZE_N + SIZE_UR + SIZE_R + SIZE_U\n",
    "print(SIZE_N, SIZE_UR, SIZE_R, SIZE_U, TOTAL)\n",
    "\n",
    "arr = np.concatenate([arr, np.flip(arr, 0)], 0)\n",
    "base_filter = np.concatenate([arr, np.flip(arr, 1)], 1)\n",
    "normal = np.tile(base_filter, (SIZE, SIZE))\n",
    "normal[:, 0:7] = 1.\n",
    "normal[:, -7:] = 1.\n",
    "normal[0:7, :] = 1.\n",
    "normal[-7:, :] = 1.\n",
    "upright = np.tile(base_filter, (SIZE - 1, SIZE - 1))\n",
    "upright = np.pad(upright, (7, 7), 'constant', constant_values = 0)\n",
    "right_filter = np.tile(base_filter, (SIZE, SIZE - 1))\n",
    "right_filter = np.pad(right_filter, ((0, 0), (7, 7)), 'constant', constant_values = 0)\n",
    "up_filter = np.tile(base_filter, (SIZE - 1, SIZE))\n",
    "up_filter = np.pad(up_filter, ((7, 7), (0, 0)), 'constant', constant_values = 0)\n",
    "\n",
    "sums = (up_filter + right_filter + upright + normal)\n",
    "up_filter /= sums\n",
    "right_filter /= sums\n",
    "upright /= sums\n",
    "normal /= sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.01588921781629324, 0.03045072354376316,\n",
    " 0.017705744933336973, 0.08037136927247047,\n",
    " 0.04978184312582016, 0.07456922113895416,\n",
    " 0.081697703525424, 0.08504692040383816,\n",
    " 0.06000244345515966, 0.0359250520914793,\n",
    " 0.0, 0.0031033563450910146,\n",
    " -0.37605552971363065, 0.0027289406443014733,\n",
    " 0.003591871485114094, 0.0057775299064815044,\n",
    " 0.0]\n",
    "\n",
    "max_all = [0.188370236158371, 0.28401015907526017,\n",
    " 0.41655176877975464, 0.5010248422622681,\n",
    " 0.45965318948030487, 0.47227429449558267,\n",
    " 0.49787560522556307, 0.5122129917144775,\n",
    " 0.6436399221420288, 0.5832849562168123,\n",
    " 0.36779049038887024, 0.717898428440094,\n",
    " 0.3190168184041977, 0.6600269079208374,\n",
    " 0.8889312487840653, 0.6703135967254639,\n",
    " 0.14510338470339812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict_folder(y_col, folder, overlap_filter = upright,\n",
    "                            normal_filter = normal, histogram_match = False):\n",
    "    \"\"\"Insert documentation here\n",
    "    \"\"\"\n",
    "    pred_files = INPUT + str(y_col) + \"/\" + str(folder) + \".hkl\"\n",
    "    reference_files = f\"../tile_data/{LANDSCAPE}/2019/processed/{str(y_col)}/{str(folder)}.hkl\"\n",
    "    \n",
    "    clipping_params = {\n",
    "        'rmax': rmax,\n",
    "        'rmin': rmin,\n",
    "        'dmax': dmax\n",
    "    }\n",
    "    \n",
    "    pred_x = []\n",
    "    x = hkl.load(pred_files)\n",
    "    if not isinstance(x.flat[0], np.floating):\n",
    "        assert np.max(x) > 1\n",
    "        x = x / 65535.\n",
    "\n",
    "    filtered = median_filter(x[0, :, :, 10], size = 5)\n",
    "    x[:, :, :, 10] = np.stack([filtered] * x.shape[0])\n",
    "\n",
    "    x[..., 11:15] = (x[..., 11:15] * 2) - 1\n",
    "    \n",
    "    x = tile_images(x)\n",
    "    pred_x = np.stack(x)   \n",
    "    for band in range(0, pred_x.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        pred_x[..., band] = np.clip(pred_x[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (pred_x[..., band] - midrange) / (rng / 2)\n",
    "        pred_x[..., band] = standardized\n",
    "\n",
    "    preds = []\n",
    "    batches = [x for x in range(0, 341, 20)] + [361]\n",
    "    for i in range(len(batches)-1):\n",
    "        batch_x = pred_x[batches[i]:batches[i+1]]\n",
    "        lengths = np.full((batch_x.shape[0], 1), 12)\n",
    "        batch_pred = sess.run(logits,\n",
    "                              feed_dict={inp:batch_x, \n",
    "                                         clipping_params['rmax']: 5,\n",
    "                                         clipping_params['rmin']: 0,\n",
    "                                         clipping_params['dmax']: 3,\n",
    "                                         length:lengths}).reshape(batch_x.shape[0], 14, 14)\n",
    "        for sample in range(batch_pred.shape[0]):\n",
    "            preds.append(batch_pred[sample, :, :])\n",
    "            \n",
    "    preds_stacked = []\n",
    "    for i in range(0, SIZE_N, SIZE):\n",
    "        preds_stacked.append(np.concatenate(preds[i:i + SIZE], axis = 1))\n",
    "    stacked = np.concatenate(preds_stacked, axis = 0) * normal\n",
    "\n",
    "    preds_overlap = []\n",
    "    for scene in range(SIZE_N, SIZE_N+SIZE_UR, SIZE - 1):\n",
    "        to_concat = np.concatenate(preds[scene:scene+ (SIZE - 1)], axis = 1)\n",
    "        preds_overlap.append(to_concat)    \n",
    "    overlapped = np.concatenate(preds_overlap, axis = 0)\n",
    "    overlapped = np.pad(overlapped, (7, 7), 'constant', constant_values = 0)\n",
    "    overlapped = overlapped * upright\n",
    "\n",
    "    preds_up = []\n",
    "    for scene in range(SIZE_N+SIZE_UR, SIZE_N+SIZE_UR+SIZE_R, SIZE):\n",
    "        to_concat = np.concatenate(preds[scene:scene+SIZE], axis = 1)\n",
    "        preds_up.append(to_concat)   \n",
    "    up = np.concatenate(preds_up, axis = 0)\n",
    "    up = np.pad(up, ((7,7), (0,0)), 'constant', constant_values = 0)\n",
    "    up = up * up_filter\n",
    "        \n",
    "    preds_right = []\n",
    "    for scene in range(SIZE_N+SIZE_UR+SIZE_R, TOTAL, SIZE - 1):\n",
    "        to_concat = np.concatenate(preds[scene:scene+SIZE-1], axis = 1)\n",
    "        preds_right.append(to_concat)   \n",
    "    right = np.concatenate(preds_right, axis = 0)\n",
    "    right = np.pad(right, ((0, 0), (7, 7)), 'constant', constant_values = 0)\n",
    "    right = right * right_filter\n",
    "    \n",
    "    stacked = stacked + overlapped + right + up\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a934251379147e58d301df8d3af854e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0204 12:54:03.245737 4683167168 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-967cb0cd9b21>\", line 7, in <module>\n",
      "    prediction = load_and_predict_folder(row, column, histogram_match = False)\n",
      "  File \"<ipython-input-8-9f67080a577d>\", line 15, in load_and_predict_folder\n",
      "    x = hkl.load(pred_files)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\", line 550, in load\n",
      "    py_container = _load(py_container, h_root_group['data'])\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\", line 634, in _load\n",
      "    subdata = load_dataset(h_group)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\", line 581, in load_dataset\n",
      "    data = load_fn(h_node)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/loaders/load_numpy.py\", line 128, in load_ndarray_dataset\n",
      "    _, _, data = get_type_and_data(h_node)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/helpers.py\", line 23, in get_type_and_data\n",
      "    data = h_node[()]\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 573, in __getitem__\n",
      "    self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/john.brandt/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/john.brandt/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "for row in tnrange((0*5), (14*5)): \n",
    "    for column in range((0*5), (12*5)):\n",
    "        output_file = f\"{OUTPUT}{str(row)}/{str(column)}.npy\"\n",
    "        input_file = f\"{INPUT}{str(row)}/{str(column)}.hkl\"\n",
    "        if os.path.exists(input_file) and not os.path.exists(output_file):\n",
    "            prediction = load_and_predict_folder(row, column, histogram_match = False)\n",
    "            if not os.path.exists(OUTPUT + str(row) + \"/\"):\n",
    "                os.makedirs(OUTPUT + str(row) + \"/\")\n",
    "            prediction = prediction[7:-7, 7:-7]\n",
    "            np.save(output_file, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2.5 Mosaic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2086d7a86fb44e5db041ca206791a1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 308000 hectares processed\n"
     ]
    }
   ],
   "source": [
    "max_x = 12*5\n",
    "max_y = 14*5\n",
    "\n",
    "start_x = 0*5\n",
    "start_y = 0*5\n",
    "\n",
    "predictions = np.full(\n",
    "    ((max_y-start_y)*126,\n",
    "     (max_x-start_x)*126), 0, dtype = np.uint8 )\n",
    "\n",
    "max_y_out = predictions.shape[0]\n",
    "max_x_out = predictions.shape[1]\n",
    "\n",
    "numb = 0\n",
    "for row in tnrange(start_y, max_y):\n",
    "    for column in range(start_x, max_x):\n",
    "        input_file = f\"{OUTPUT}{str(row)}/{str(column)}.npy\"\n",
    "        if os.path.exists(input_file):\n",
    "            prediction = np.load(input_file)\n",
    "            x_value = (column-start_x) *126\n",
    "            y_value = (max_y_out - ((row - start_y + 1) *126))\n",
    "            if (row % 5 == 0) and (column % 5 == 0):\n",
    "                numb += 1\n",
    "            predictions[y_value:y_value+126, \n",
    "                        x_value:x_value+126,\n",
    "                        ] = (prediction * 255).astype(np.uint8)\n",
    "            \n",
    "predictions[predictions < 41] = 0.\n",
    "print(f\"There are {numb*4000} hectares processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Sharpen predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_new(arr, thresh):\n",
    "    \"\"\"Not currently used. Identifies small trees that may be below the\n",
    "       threshold for binary map creation.\n",
    "    \"\"\"\n",
    "    adding = 0\n",
    "    stacked = np.copy(arr)\n",
    "    for window_x in tnrange(2, stacked.shape[0]-2, 1):\n",
    "        for window_y in range(2, stacked.shape[1]-2, 1):\n",
    "            #\n",
    "            five_w = stacked[window_x-2:window_x+3, window_y-2:window_y+3]\n",
    "            three_w = stacked[window_x-1:window_x+2, window_y-1:window_y+2]\n",
    "            \n",
    "            n_five_above = len(five_w[np.argwhere(five_w > 0.15)])\n",
    "            n_three_above = len(three_w[np.argwhere(three_w > 0.15)])\n",
    "            \n",
    "            n_five_below = len(five_w[np.argwhere(five_w < thresh)])\n",
    "            \n",
    "            \n",
    "            if n_five_below >= 24:                 \n",
    "                # if less than 2 of the 5x5 are positive\n",
    "                if n_three_above >= 2 and n_three_above < 6:            \n",
    "                    # and at least 2 of the 3x3 are above 0.1\n",
    "                    if n_three_above <= (n_five_above + 4):  \n",
    "                        # and less than 1/4 of the outer border is above 0.1\n",
    "                        if np.argmax(three_w) == 4:          \n",
    "                            # and the center of the 3 x 3 is the largest\n",
    "                            stacked[window_x, window_y] = -1.\n",
    "                            adding += 1\n",
    "    stacked[np.where(stacked == -1)] = 1.\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = predictions\n",
    "\n",
    "threshold = False\n",
    "if threshold:\n",
    "    stacked = recover_new(predictions, 0.3)\n",
    "    stacked[np.where(stacked > thresh_p)] = 0.71\n",
    "    stacked[np.where(stacked < thresh_p)] = -1\n",
    "    stacked[np.where(stacked == 1.0)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "if plot:\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(stacked, cbar = False, cmap = \"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Write GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../project-monitoring/el-salvador/sonsonate/acajutla/2018.tif\n"
     ]
    }
   ],
   "source": [
    "point = bounding_box(coords, (max_x*1260)-0, ((max_y)*1260)-0, expansion = 0)\n",
    "west = point[1][0]\n",
    "east = point[0][0]\n",
    "north = point[0][1]\n",
    "south = point[1][1]\n",
    "\n",
    "stacked[np.where(stacked < 0)] = 0.\n",
    "stacked = stacked.astype(np.uint8)\n",
    "transform = rasterio.transform.from_bounds(west = west, south = south,\n",
    "                                           east = east, north = north,\n",
    "                                           width = stacked.shape[1], \n",
    "                                           height = stacked.shape[0])\n",
    "\n",
    "print(\"Writing\", TIF_OUTPUT)\n",
    "new_dataset = rasterio.open(TIF_OUTPUT, 'w', driver = 'GTiff',\n",
    "                           height = stacked.shape[0], width = stacked.shape[1], count = 1,\n",
    "                           dtype = 'uint8',#str(stacked.dtype),\n",
    "                           crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs',\n",
    "                           transform=transform)\n",
    "new_dataset.write(stacked, 1)\n",
    "new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Cloud optimized Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 630, 630\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!gdal_translate ../../ce-hosting/includes/drc-kafubu.tif ../tile_data/cog/drc-kafubu.tif \\\n",
    "               -co TILED=YES -co COMPRESS=LZW\n",
    "!gdaladdo -r average -ro ../tile_data/cog/drc-kafubu.tif 2 4 8 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 One-hectare tree cover Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = np.reshape(stacked, (stacked.shape[0] // 10, 10, stacked.shape[1] // 10, 10))\n",
    "summed = np.mean(summed, (1, 3))\n",
    "\n",
    "summed = summed.astype(np.float32)\n",
    "transform = rasterio.transform.from_bounds(west = west, south = south,\n",
    "                                           east = east, north = north,\n",
    "                                           width = summed.shape[1], height = summed.shape[1])\n",
    "\n",
    "new_dataset = rasterio.open('../../ce-hosting/includes/bonanza1.tif', 'w', driver = 'GTiff',\n",
    "                           height = summed.shape[1], width = summed.shape[1], count = 1,\n",
    "                           dtype = 'float32',#str(stacked.dtype),\n",
    "                           crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs',\n",
    "                           transform=transform)\n",
    "new_dataset.write(summed, 1)\n",
    "new_dataset.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
